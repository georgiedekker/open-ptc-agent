"""Test script for agent prompt generation.

This script demonstrates:
1. Agent receives proper prompts with MCP tool information
2. Template-based prompt generation works correctly
"""

import asyncio
from unittest.mock import Mock, MagicMock

from src.agent import PTCAgent
from src.agent.prompts import get_loader, reset_loader
from src.config import CoreConfig as Config
from src.ptc_core.mcp_registry import MCPRegistry, MCPToolInfo


def create_mock_mcp_registry() -> MCPRegistry:
    """Create a mock MCP registry with sample tools."""
    registry = Mock(spec=MCPRegistry)

    # Mock tools from different MCP servers
    tavily_tools = [
        MCPToolInfo(
            name="tavily_search",
            description="Search the web using Tavily search engine",
            input_schema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "max_results": {"type": "integer", "description": "Maximum results", "default": 10}
                },
                "required": ["query"]
            },
            server_name="tavily"
        )
    ]

    filesystem_tools = [
        MCPToolInfo(
            name="read_file",
            description="Read contents of a file",
            input_schema={
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "File path to read"}
                },
                "required": ["path"]
            },
            server_name="filesystem"
        ),
        MCPToolInfo(
            name="write_file",
            description="Write content to a file",
            input_schema={
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "File path to write"},
                    "content": {"type": "string", "description": "Content to write"}
                },
                "required": ["path", "content"]
            },
            server_name="filesystem"
        ),
        MCPToolInfo(
            name="list_directory",
            description="List contents of a directory",
            input_schema={
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Directory path to list"}
                },
                "required": ["path"]
            },
            server_name="filesystem"
        )
    ]

    github_tools = [
        MCPToolInfo(
            name="create_issue",
            description="Create a new GitHub issue",
            input_schema={
                "type": "object",
                "properties": {
                    "repo": {"type": "string", "description": "Repository name (owner/repo)"},
                    "title": {"type": "string", "description": "Issue title"},
                    "body": {"type": "string", "description": "Issue body"}
                },
                "required": ["repo", "title"]
            },
            server_name="github"
        )
    ]

    # Mock get_all_tools to return organized tools
    registry.get_all_tools.return_value = {
        "tavily": tavily_tools,
        "filesystem": filesystem_tools,
        "github": github_tools
    }

    return registry


def create_mock_config():
    """Create a mock config."""
    config = Mock()

    # Mock LLM client
    mock_llm = MagicMock()
    config.get_llm_client.return_value = mock_llm

    # Mock LLM definition
    config.llm_definition = Mock()
    config.llm_definition.provider = "openai"
    config.llm_definition.model_id = "gpt-4"

    # Mock MCP config with tool_exposure_mode and servers
    config.mcp = Mock()
    config.mcp.tool_exposure_mode = "summary"
    config.mcp.servers = []  # Empty list for servers

    return config


def print_section(title: str, content: str):
    """Pretty print a section."""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)
    print(content)
    print("="*80 + "\n")


async def main():
    """Demonstrate template-based prompt generation."""

    print("\n" + "ğŸ” PROMPT TEMPLATE TEST: Jinja2-based Prompt Generation".center(80))
    print("="*80)

    # Reset loader to ensure fresh templates
    reset_loader()

    # Create mocks
    config = create_mock_config()
    mcp_registry = create_mock_mcp_registry()

    # Create agent
    agent = PTCAgent(config)

    # Get the tool summary that should be in the prompt
    tool_summary = agent._get_tool_summary(mcp_registry)

    print_section(
        "ğŸ“Š TOOL SUMMARY (Generated by _get_tool_summary)",
        tool_summary
    )

    # Get the actual system prompt the agent uses
    system_prompt = agent._build_system_prompt(tool_summary)

    print_section(
        "âœ… SYSTEM PROMPT (Generated from templates)",
        system_prompt[:2000] + "\n\n... (truncated for display)"
    )

    # Test template loader directly
    loader = get_loader()
    print_section(
        "ğŸ“„ RESEARCHER TEMPLATE (from loader)",
        loader.get_subagent_prompt("researcher", date="2024-01-15")[:1000] + "\n\n... (truncated)"
    )

    # Analysis
    print("\n" + "ğŸ“‹ TEMPLATE SYSTEM OVERVIEW".center(80))
    print("="*80)
    print("""
TEMPLATE-BASED PROMPT SYSTEM:
  The prompt system now uses Jinja2 templates stored in .md.j2 files.

DIRECTORY STRUCTURE:
  src/agent/prompts/
  â”œâ”€â”€ templates/
  â”‚   â”œâ”€â”€ components/     # Reusable building blocks
  â”‚   â”‚   â”œâ”€â”€ search_first.md.j2
  â”‚   â”‚   â”œâ”€â”€ image_upload.md.j2
  â”‚   â”‚   â”œâ”€â”€ mcp_usage.md.j2
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â”œâ”€â”€ agents/         # Agent-specific templates
  â”‚   â”‚   â”œâ”€â”€ ptc_agent.md.j2
  â”‚   â”‚   â”œâ”€â”€ researcher.md.j2
  â”‚   â”‚   â””â”€â”€ general.md.j2
  â”‚   â””â”€â”€ code_execution/ # Code execution prompts
  â”‚       â””â”€â”€ ...
  â”œâ”€â”€ config/prompts.yaml # Configuration & defaults
  â”œâ”€â”€ loader.py           # Template loading
  â””â”€â”€ formatter.py        # Tool summary formatting

KEY FEATURES:
  - Modular components with {% include %} composition
  - Conditional rendering with {% if %} blocks
  - Variable substitution with {{ variable }}
  - Template object caching for performance
  - YAML-based configuration for defaults

TOKEN EFFICIENCY:
  - Summary mode: Brief listing of servers + filesystem navigation hints
  - Detailed mode: Full tool signatures in prompt
  - Both modes support on-demand doc reading for full details
    """)
    print("="*80 + "\n")

    print("âœ¨ Test complete! Template system is working.\n")


if __name__ == "__main__":
    asyncio.run(main())
